Task 1: Ansible Installation and Configuration
- Install ansible package on the control node (including any dependencies) and configure the following:
    - Create a regular user ansible with the password of devops. Use this user for all sample exam
      tasks and playbooks, unless you are working on the task #2 that requires creating the ansible
      user on inventory hosts. You have root access to all five servers.
    - All playbooks and other Ansible configuration that you create for this sample exam should be stored in
      /home/ansible/plays.
- Create a configuration file /home/ansible/plays/ansible.cfg to meet the following requirements:
    - The roles path should include /home/ansible/plays/roles, as well as any other path that may be required
      for the course of the sample exam.
    - The inventory file path is /home/ansible/plays/inventory.
    - Privilege escallation is disabled by default.
    - Ansible should be able to manage 10 hosts at a single time.
    - Ansible should connect to all managed nodes using the ansible user.
- Create an inventory file /home/ansible/plays/inventory with the following:
    ansible0.example.com is a member of the proxy host group.
    ansible1.example.com is a member of the webservers host group.
    ansible2.example.com is a member of the webservers host group.
    ansible3.example.com is a member of the database host group.
    proxy and webservers is a member of the frontend host group.

Task 2: Configure Localhost services
- Create a playbook with the name /home/ansible/plays/setupreposerver.yml to set up the control host
  as a repository host.
  Make sure this host meets the following requirements, which must be done by the playbook:
  - The RHEL installation ISO is loop-mounted on the directory /var/ftp/repo with appropriate options.
  - Allow ftp traffic in firewall.
  - The vsftpd service is started and enabled,
    and it allows anonymous user access to the /var/ftp/repo directory.

Task 3: Configure managed hosts
- Create a playbook /home/ansible/plays/setuprepoclient.yml that configures managed servers as repository
  clients to the repository server that you have set up in the previous task.
  This playbook must perform the following tasks:
  - Disable any currently existing repository.
  - Enable access to the repository on ansible-control.example.com.

Task 4 : Ad-Hoc Commands
- Generate an SSH keypair on the control node. You can perform this step manually.
- Write a script /home/ansible/plays/adhoc that uses Ansible ad-hoc commands to achieve the following:
    - User ansible is created on all inventory hosts (not the control node).
    - SSH key (that you generated) is copied to all inventory hosts for the ansible user and stored in
      /home/ansible/.ssh/authorized_keys.
    - The ansible user is allowed to elevate privileges on all inventory hosts without having to provide a password.

After running the adhoc script, you should be able to SSH into all inventory hosts using the ansible user
without password, as well as a run all privileged commands.

Task 5: File Content
- Create a playbook /home/ansible/plays/motd.yml that runs on all inventory hosts and does the following:
    - The playbook should replace any existing content of /etc/motd with text. Text depends on the host group.
    - On hosts in the proxy host group the line should be “Welcome to HAProxy server”.
    - On hosts in the webservers host group the line should be “Welcome to Apache server”.
    - On hosts in the database host group the line should be “Welcome to MySQL server”.
#TODO check the play book
Task 6: File Content - continue
- Create a playbook with the name /home/ansible/plays/sysreport.yml that generates a file on the managed server.
  The file should have the name hwtemplate.txt and the following contents:
    NAME=
    IPADDRESS=
    TOTAL_MEMORY=
    NIC_NAME=
    SECOND_NIC_NAME=
  Use this file to generate a report on the managed servers. To do so, copy the file to /root/report.txt,
  and have your playbook modify it, but do not overwrite current settings. Apply the following requirements:
  - NAME= gets the FQDN of the managed host as argument.
  -	IPADDRESS= gets the IP address of the managed host.
  -	TOTAL_MEMORY= gets the total amount of memory on the managed host.
  -	NIC_NAME=gets the name of the network card on the host.
  - If the host has a second network card, SECOND_NIC_NAME should get the name of that network card.
    If the managed host has no second network card, the playbook should set SECOND_NIC_NAME=NONE.

Task 7: Configure SSH Server
- Create a playbook /home/ansible/plays/sshd.yml that runs on all inventory hosts and configures SSHD daemon as
  follows:
    banner is set to /etc/motd
    X11Forwarding is disabled
    MaxAuthTries is set to 3

Task 8: Ansible Vault
- Create Ansible vault file /home/ansible/plays/vars/secret.yml. Encryption/decryption password is "insecure".
- Add the following variables to the vault:
    user_password with value of devops
    database_password with value of devops
- Rekey encrypted file with new password "devops"
- Store Ansible vault password in the file /home/ansible/plays/vault_key

Task 9: Users and Groups
You have been provided with the list of users below.
Use /home/ansible/plays/vars/user_list.yml file to save this content.

---
users:
  - username: alice
    uid: 1201
  - username: vincent
    uid: 1202
  - username: sandy
    uid: 2201
  - username: patrick
    uid: 2202

- Create a playbook /home/ansible/plays/users.yml that uses the vault file /home/ansible/plays/secret.yml
  to achieve the following:
    - Users whose user ID starts with 1 should be created on servers in the webservers host group.
      User password should be used from the user_password variable.
    - Users whose user ID starts with 2 should be created on servers in the database host group.
      User password should be used from the user_password variable.
    - All users should be members of a supplementary group wheel.
    - Shell should be set to /bin/bash for all users.
    - Account passwords should use the SHA512 hash format.
    - Each user should have an SSH key uploaded (use the SSH key that you created previously, see task #2).

After running the playbook, users should be able to SSH into their respective servers without passwords.

Task 10: Scheduled Tasks
- Create a playbook /home/ansible/plays/regular_tasks.yml that runs on servers in the proxy host group and does the
  following:
    - A root crontab record is created that runs every hour.
    - The cron job appends the file /var/log/time.log with the output from the date command.

Task 11: Software Repositories
- Create a playbook /home/ansible/plays/repository.yml that runs on servers in the database host group and does the
  following:
    - A YUM repository file is created.
    - The name of the repository is mysql56-community.
    - The description of the repository is “MySQL 5.6 YUM Repo”.
    - Repository baseurl is http://repo.mysql.com/yum/mysql-5.6-community/el/7/x86_64/.
    - Repository GPG key is at http://repo.mysql.com/RPM-GPG-KEY-mysql.
    - Repository GPG check is enabled.
    - Repository is enabled.

Task 12: Create and Work with Roles
- Create a role called sample-mysql and store it in /home/ansible/plays/roles. The role should satisfy the
  following requirements:
    - A primary partition number 1 of size 800MB on device /dev/sdb is created.
    - An LVM volume group called vg_database is created that uses the primary partition created above.
    - An LVM logical volume called lv_mysql is created of size 512MB in the volume group vg_database.
    - An XFS filesystem on the logical volume lv_mysql is created.
    - Logical volume lv_mysql is permanently mounted on /mnt/mysql_backups.
    - mysql-community-server package is installed.
    - Firewall is configured to allow all incoming traffic on MySQL port TCP 3306.
    - MySQL root user password should be set from the variable database_password (see task #5).
    - MySQL server should be started and enabled on boot.
    - MySQL server configuration file is generated from the my.cnf.j2 Jinja2 template with the following content:
    
[mysqld]
bind_address = {{ ansible_default_ipv4.address }}
skip_name_resolve
datadir=/var/lib/mysql
socket=/var/lib/mysql/mysql.sock

symbolic-links=0
sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES

[mysqld_safe]
log-error=/var/log/mysqld.log
pid-file=/var/run/mysqld/mysqld.pid

- Create a playbook /home/ansible/plays/mysql.yml that uses the role and runs on hosts in the database host group.

Task 13: Create and Work with Roles - continue
- Create a role called sample-apache and store it in /home/ansible/plays/roles. The role should satisfy the
  following requirements:
    - The httpd, mod_ssl and php packages are installed. Apache service is running and enabled on boot.
    - Firewall is configured to allow all incoming traffic on HTTP port TCP 80 and HTTPS port TCP 443.
    - Apache service should be restarted every time the file /var/www/html/index.html is modified.
    - A Jinja2 template file index.html.j2 is used to create the file /webcontent/index.html with the following
      content:
        Welcome to this webserver.
        The server is managed by: WEB_ADMIN
        The address of the server is: IPV4ADDRESS
        The server FQDN is: HOST_FQDN.
    - Use a variable to set WEB_ADMIN to anna. The variable should be set by using inclusion of a
      file that is created for servers in the group webservers only.
    - Create a symbolic link in /var/www/html/index.html that links to the file /webcontent/index.html,
      and ensure the contents of this file are visible from remote hosts.

Create a playbook /home/ansible/plays/apache.yml that uses the role and runs on hosts in the webservers host group.

Task 14: Download Roles From Ansible Galaxy and Use Them
- Use Ansible Galaxy to download and install geerlingguy.haproxy role in /home/ansible/plays/roles.
- The role should be installed using /home/ansible/plays/requirements.yml, and should be configured:
    - source: https://github.com/geerlingguy/ansible-role-haproxy.git
    - name: haproxy
- Create a playbook /home/ansible/plays/haproxy.yml that runs on servers in the proxy host group and does the
  following:
    - Use haproxy role to load balance request between hosts in the webservers host group.
    - Use roundrobin load balancing method.
    - HAProxy backend servers should be configured for HTTP only (port 80).
    - Firewall is configured to allow all incoming traffic on port TCP 80.

If your playbook works, then doing “curl http://ansible0.example.com/” should return output from the
web server (see task #10). Running the command again should return output from the other web server.

Task 15: Security
- Create a playbook /home/ansible/plays/selinux.yml that runs on hosts in the webservers host group and does the
  following:
    - Uses the selinux RHEL system role.
    - Enables httpd_can_network_connect SELinux boolean.
    - The change must survive system reboot.

Task 16: NTP
- Create a playbook /home/ansible/plays/setservertime.yml that set NTP server on ansible-control.example.com,
  the server should serve managed hosts as NTP server.
- Use the RHEL system role that manages time in a playbook with the name /home/ansible/plays/settime.yml.
  Ensure that ansible-control.example.com is used as the time server, and set the appropriate parameter that allows
  changing time even if a large difference exists between time on the managed machine and time on the time server.
  At the end of the playbook, verify that time is synchronized. If this is not the case,
  the playbook should print the text “Unfortunately time could not be synchronized”.

Task 17: Use Conditionals to Control Play Execution
- Create a playbook /home/ansible/plays/sysctl.yml that runs on all inventory hosts and does the following:
    - If a server has more than 2048MB of RAM, then parameter vm.swappiness is set to 10.
    - If a server has less than 2048MB of RAM, then the following error message is displayed:
        "Server memory less than 2048MB"

Task 18: Use Archiving
- Create a playbook /home/ansible/plays/archive.yml that runs on hosts in the database host group and does the
  following:
    - A file /mnt/mysql_backups/database_list.txt is created that contains the following line: dev,test,qa,prod.
    - A gzip archive of the file /mnt/mysql_backups/database_list.txt is created and stored in
      /mnt/mysql_backups/archive.gz.

Task 19: Work with Ansible Facts
- Create a playbook /home/ansible/plays/facts.yml that runs on hosts in the database host group and does the
  following:
    - A custom Ansible fact server_role=mysql is created that can be retrieved from ansible_local.custom.sample_exam
      when using Ansible setup module.

Task 20: Software Packages
- Create a playbook /home/ansible/plays/packages.yml that runs on all inventory hosts and does the following:
    - Installs tcpdump and mailx packages on hosts in the proxy host groups.
    - Installs lsof and mailx and packages on hosts in the database host groups.

Task 21: Services
- Create a playbook /home/ansible/plays/target.yml that runs on hosts in the webservers host group and does the
  following:
    - Sets the default boot target to multi-user.

Task 22. Create and Use Templates to Create Customised Configuration Files
- Create a playbook /home/ansible/plays/server_list.yml that does the following:
    - Playbook uses a Jinja2 template /home/ansible/template/server_list.j2 to create a file /etc/server_list.txt on hosts in the database
      host group.
    - The file /etc/server_list.txt is owned by the ansible user.
    - File permissions are set to 0600.
    - SELinux file label should be set to net_conf_t.
    - The content of the file is a list of FQDNs and IP address of all inventory hosts.

After running the playbook, the content of the file /etc/server_list.txt should be the following, mind the list order:
    HOST1_FQDN: HOST1_IP
    HOST2_FQDN: HOST2_IP
    HOST3_FQDN: HOST3_IP
    HOST4_FQDN: HOST4_IP

Note: if the FQDN of any inventory host changes, re-running the playbook should update the file with the new values.

Task 23. Storage
- Create a playbook /home/ansible/plays/storage.yml that does the following:
    - A primary partition number 1 on device /dev/sdb is created.
    - An LVM volume group called vg_data is created that uses the primary partition created above.
    - An LVM logical volume called lv_data is created of size 800MB in the volume group vg_data.
    - An ext4 filesystem on the logical volume lv_data is created.
    - Logical volume lv_data is permanently mounted on /data.
    - If device does not exists playbook should issue message:
      "Device /dev/sdb on HOST_FQDN does not exists."
      where HOST_FQDN is host's FQDN.
    - If there is not enough storage on volume group vg_data playbook should issue message:
      "VG group vg_data doesn't have enough storage".